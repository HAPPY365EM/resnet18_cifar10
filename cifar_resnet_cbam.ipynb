{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM0rCzNvaUxmUjz5DIxTMJJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HAPPY365EM/resnet18_cifar10/blob/main/cifar_resnet_cbam.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QIV-G7OgklAK"
      },
      "outputs": [],
      "source": [
        "# ===== 完整独立的CIFAR10训练方案 =====\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import time\n",
        "from google.colab import drive\n",
        "\n",
        "# 1. 挂载Google Drive（防止断网丢失数据）\n",
        "drive.mount('/content/drive')\n",
        "save_dir = '/content/drive/MyDrive/cifar_resnet_cbam'\n",
        "\n",
        "# 2. 检查GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"使用设备: {device}\")\n",
        "\n",
        "# 3. 准备数据集\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))\n",
        "])\n",
        "\n",
        "# 下载CIFAR10数据集\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "class ChannelAttention(nn.Module):\n",
        "    def __init__(self, in_channels, reduction_ratio=16):\n",
        "        super().__init__()\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(in_channels, in_channels // reduction_ratio),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(in_channels // reduction_ratio, in_channels),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # 平均池化\n",
        "        avg_pool = self.avg_pool(x)\n",
        "        # 重塑为 [batch_size, channels]\n",
        "        avg_out = avg_pool.view(avg_pool.size(0), avg_pool.size(1))\n",
        "        avg_out = self.fc(avg_out)\n",
        "\n",
        "        # 最大池化\n",
        "        max_pool = self.max_pool(x)\n",
        "        # 重塑为 [batch_size, channels]\n",
        "        max_out = max_pool.view(max_pool.size(0), max_pool.size(1))\n",
        "        max_out = self.fc(max_out)\n",
        "\n",
        "        # 合并并恢复维度\n",
        "        out = avg_out + max_out\n",
        "        # [batch_size, channels] -> [batch_size, channels, 1, 1]\n",
        "        return out.unsqueeze(-1).unsqueeze(-1)\n",
        "\n",
        "class SpatialAttention(nn.Module):\n",
        "    def __init__(self, kernel_size=7):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(2, 1, kernel_size, padding=kernel_size//2)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
        "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
        "        concat = torch.cat([avg_out, max_out], dim=1)\n",
        "        return self.sigmoid(self.conv(concat))\n",
        "\n",
        "class CBAM(nn.Module):\n",
        "    def __init__(self, in_channels, reduction_ratio=16):\n",
        "        super().__init__()\n",
        "        self.channel_att = ChannelAttention(in_channels, reduction_ratio)\n",
        "        self.spatial_att = SpatialAttention()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = x * self.channel_att(x)\n",
        "        out = out * self.spatial_att(out)\n",
        "        return out\n",
        "\n",
        "# ===== 修改BasicBlock =====\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1, use_cbam=True):  # 添加use_cbam参数\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.use_cbam = use_cbam\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        # 添加CBAM模块\n",
        "        if use_cbam:\n",
        "            self.cbam = CBAM(planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = torch.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "\n",
        "        # 添加注意力机制\n",
        "        if self.use_cbam:\n",
        "            out = self.cbam(out)\n",
        "\n",
        "        out += self.shortcut(x)\n",
        "        out = torch.relu(out)\n",
        "        return out\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=10, use_cbam=True):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_planes = 64\n",
        "        self.use_cbam = use_cbam\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1, use_cbam=use_cbam)\n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2, use_cbam=use_cbam)\n",
        "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2, use_cbam=use_cbam)\n",
        "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2, use_cbam=use_cbam)\n",
        "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride, use_cbam):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride, use_cbam))\n",
        "            self.in_planes = planes * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = torch.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = nn.functional.avg_pool2d(out, 4)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "def ResNet18(use_cbam=True):  # 独立函数定义\n",
        "    return ResNet(BasicBlock, [2, 2, 2, 2], use_cbam=use_cbam)\n",
        "\n",
        "def visualize_predictions(model, test_loader, classes, num_samples=15, save_path=None):\n",
        "    \"\"\"\n",
        "    可视化模型预测结果（正确和错误样本）\n",
        "    \"\"\"\n",
        "    # 反归一化转换器\n",
        "    inv_normalize = transforms.Normalize(\n",
        "        mean=[-0.4914/0.247, -0.4822/0.243, -0.4465/0.261],\n",
        "        std=[1/0.247, 1/0.243, 1/0.261]\n",
        "    )\n",
        "\n",
        "    # 获取测试数据\n",
        "    dataiter = iter(test_loader)\n",
        "    images, labels = next(dataiter)\n",
        "\n",
        "    # GPU处理\n",
        "    images = images.to(device)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "    # 创建可视化\n",
        "    fig = plt.figure(figsize=(15, 8))\n",
        "    for i in range(num_samples):\n",
        "        ax = fig.add_subplot(3, 5, i+1, xticks=[], yticks=[])\n",
        "        # 反归一化并转换通道\n",
        "        img = inv_normalize(images[i]).cpu().permute(1, 2, 0).numpy()\n",
        "        img = np.clip(img, 0, 1)\n",
        "        ax.imshow(img)\n",
        "\n",
        "        # 设置标题颜色\n",
        "        color = 'green' if predicted[i] == labels[i] else 'red'\n",
        "        true_label = classes[labels[i]]\n",
        "        pred_label = classes[predicted[i].item()]\n",
        "        ax.set_title(f\"True: {true_label}\\nPred: {pred_label}\", color=color)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    if save_path:\n",
        "        plt.savefig(save_path, dpi=300)\n",
        "    plt.show()\n",
        "\n",
        "def visualize_errors(error_samples, classes, save_path=None):\n",
        "    \"\"\"\n",
        "    可视化错误样本（4×4网格）\n",
        "    \"\"\"\n",
        "    fig, axes = plt.subplots(4, 4, figsize=(16, 12))\n",
        "    for i, sample in enumerate(error_samples[:16]):\n",
        "        ax = axes[i//4, i%4]\n",
        "        # 反归一化\n",
        "        img = sample['image']\n",
        "        img = img * torch.tensor([0.247, 0.243, 0.261]).view(3,1,1) + torch.tensor([0.4914, 0.4822, 0.4465]).view(3,1,1)\n",
        "        img = img.permute(1, 2, 0).numpy()\n",
        "        ax.imshow(np.clip(img, 0, 1))\n",
        "        ax.set_title(f\"T:{classes[sample['true']]}→P:{classes[sample['pred']]}\\nConf:{sample['confidence']:.2f}\",\n",
        "                    color='red')\n",
        "        ax.axis('off')\n",
        "    plt.tight_layout()\n",
        "    if save_path:\n",
        "        plt.savefig(save_path, dpi=300)\n",
        "    plt.show()\n",
        "\n",
        "# 5. 训练函数\n",
        "def train_model():\n",
        "    net = ResNet18().to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(net.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
        "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)\n",
        "\n",
        "    train_losses = []\n",
        "    test_accuracies = []\n",
        "\n",
        "    print(\"开始训练...\")\n",
        "    for epoch in range(100):  # 训练100个epoch\n",
        "        net.train()\n",
        "        running_loss = 0.0\n",
        "        for i, data in enumerate(trainloader, 0):\n",
        "            inputs, labels = data\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        train_losses.append(running_loss / len(trainloader))\n",
        "        scheduler.step()\n",
        "\n",
        "        # 测试准确率\n",
        "        accuracy, _ = test_model(net)\n",
        "        test_accuracies.append(accuracy)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/100 - Loss: {train_losses[-1]:.4f} - Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "    # 保存模型\n",
        "    torch.save(net.state_dict(), f\"{save_dir}/resnet_cbam_cifar10.pth\")\n",
        "\n",
        "    return net, train_losses, test_accuracies\n",
        "\n",
        "# 6. 测试函数 (修改后)\n",
        "def test_model(net=None, save_errors=True):\n",
        "    if net is None:\n",
        "        net = ResNet18().to(device)\n",
        "        net.load_state_dict(torch.load(f\"{save_dir}/resnet_cbam_cifar10.pth\"))\n",
        "\n",
        "    net.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    all_errors = []  # 存储错误样本信息\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in testloader:\n",
        "            images, labels = data\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = net(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            # 收集错误样本\n",
        "            if save_errors:\n",
        "                err_idx = (predicted != labels).nonzero(as_tuple=True)[0]\n",
        "                for idx in err_idx:\n",
        "                    # 计算预测置信度\n",
        "                    confidence = torch.nn.functional.softmax(outputs[idx], 0)[predicted[idx]].item()\n",
        "                    all_errors.append({\n",
        "                        'image': images[idx].cpu().clone(),\n",
        "                        'true': labels[idx].item(),\n",
        "                        'pred': predicted[idx].item(),\n",
        "                        'confidence': confidence\n",
        "                    })\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f\"测试准确率: {accuracy:.2f}%\")\n",
        "\n",
        "    # 保存错误样本\n",
        "    if save_errors and all_errors:\n",
        "        torch.save(all_errors[:20], f\"{save_dir}/error_samples.pth\")\n",
        "\n",
        "    return accuracy, all_errors[:20]  # 返回错误样本用于可视化\n",
        "\n",
        "# 在测试代码中添加特征可视化\n",
        "def visualize_attention(model, img, save_path=None):\n",
        "    \"\"\"可视化注意力热力图（在原始图像上叠加）\"\"\"\n",
        "    model.eval()\n",
        "    # 获取最后一个CBAM层的空间注意力图\n",
        "    activations = []\n",
        "    def hook_fn(module, input, output):\n",
        "        activations.append(output.detach().cpu())  # 直接获取输出张量\n",
        "\n",
        "    # 注册钩子\n",
        "    hook = model.layer4[-1].cbam.spatial_att.register_forward_hook(hook_fn)\n",
        "\n",
        "    # 前向传播\n",
        "    with torch.no_grad():\n",
        "        model(img.unsqueeze(0).to(device))\n",
        "\n",
        "    # 移除钩子\n",
        "    hook.remove()\n",
        "\n",
        "    # 绘制热图\n",
        "    plt.figure(figsize=(10, 5))\n",
        "\n",
        "    # 原始图像\n",
        "    plt.subplot(1, 2, 1)\n",
        "    # 反归一化\n",
        "    img_disp = img.cpu().permute(1, 2, 0).numpy()\n",
        "    img_disp = img_disp * np.array([0.247, 0.243, 0.261]) + np.array([0.4914, 0.4822, 0.4465])\n",
        "    plt.imshow(np.clip(img_disp, 0, 1))\n",
        "    plt.title('Original Image')\n",
        "    plt.axis('off')\n",
        "\n",
        "    # 注意力热力图叠加\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.imshow(np.clip(img_disp, 0, 1))\n",
        "    # 空间注意力图是单通道的，所以使用索引[0,0]\n",
        "    plt.imshow(activations[0][0, 0], alpha=0.5, cmap='jet')\n",
        "    plt.title('Attention Heatmap')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    if save_path:\n",
        "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "# 7. 可视化函数\n",
        "def visualize_results(train_losses, test_accuracies):\n",
        "    # 绘制学习曲线\n",
        "    plt.figure(figsize=(12, 4))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(train_losses, label='训练损失')\n",
        "    plt.title('训练损失曲线')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(test_accuracies, label='测试准确率')\n",
        "    plt.title('测试准确率曲线')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy (%)')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.savefig(f\"{save_dir}/cbam_learning_curves.png\")\n",
        "    plt.show()\n",
        "\n",
        "    # 保存最终结果\n",
        "    final_accuracy = test_accuracies[-1]\n",
        "    with open(f\"{save_dir}/results.txt\", \"w\") as f:\n",
        "        f.write(f\"最终测试准确率: {final_accuracy:.2f}%\\n\")\n",
        "        f.write(f\"训练时间: {training_time:.2f}分钟\\n\")\n",
        "\n",
        "# 8. 主执行流程\n",
        "start_time = time.time()\n",
        "\n",
        "# 创建保存目录\n",
        "!mkdir -p \"{save_dir}\"\n",
        "\n",
        "# 训练模型\n",
        "trained_net, train_losses, test_accuracies = train_model()\n",
        "\n",
        "# 记录训练时间\n",
        "training_time = (time.time() - start_time) / 60\n",
        "\n",
        "# 最终测试（启用错误收集）\n",
        "final_accuracy, error_samples = test_model(trained_net, save_errors=True)\n",
        "\n",
        "# 可视化结果\n",
        "visualize_results(train_losses, test_accuracies)\n",
        "\n",
        "# ===== 调用可视化函数 =====\n",
        "# 1. 预测结果可视化\n",
        "visualize_predictions(\n",
        "    trained_net, testloader, classes,\n",
        "    save_path=f\"{save_dir}/cbam_prediction_samples.png\"\n",
        ")\n",
        "\n",
        "# 2. 错误样本可视化\n",
        "if error_samples:\n",
        "    visualize_errors(\n",
        "        error_samples, classes,\n",
        "        save_path=f\"{save_dir}/cbam_error_analysis.png\"\n",
        "    )\n",
        "\n",
        "# 3. 注意力可视化（选择第一个测试样本）\n",
        "sample_img = next(iter(testloader))[0][0]  # 获取第一个测试样本\n",
        "visualize_attention(\n",
        "    trained_net, sample_img,\n",
        "   save_path=f\"{save_dir}/cbam_attention_heatmap.png\"\n",
        ")\n",
        "\n",
        "# 下载结果文件\n",
        "from google.colab import files\n",
        "files.download(f\"{save_dir}/cbam_learning_curves.png\")\n",
        "files.download(f\"{save_dir}/results.txt\")\n",
        "\n",
        "print(\"所有操作已完成！\")"
      ]
    }
  ]
}